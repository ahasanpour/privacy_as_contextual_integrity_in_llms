# Privacy as Contextual Integrity in LLMs

These papers addressed Contextual Integrity in LLMs (large language models). Contributions welcome!

| Year | Paper | Dataset/Benchmark | Repository/Webpage 
|------| --- |-------------------| --- |
|2023| Automating Governing Knowledge Commons and Contextual Integrity (GKC-CI) Privacy Policy Annotations with Large Language Models ||
| 2024 | Can llms keep a secret? testing privacy implications of language models via contextual integrity theory|         CONFAIDE          |https://confaide.github.io/
| 2024 | Operationalizing Contextual Integrity in Privacy-Conscious Assistants | 
| 2024 | Large Language Models Can Be Contextual Privacy Protection Learners|| https://github.com/Yijia-Xiao/PPLM
| 2024 | GOLDCOIN: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory |GOLDCOIN-HIPAA|https://github.com/HKUST-KnowComp/GoldCoin
|2024 | Protecting Users From Themselves: Safeguarding Contextual Privacy in Interactions with Conversational Agents| 
|2024 | LLM-CI: Assessing Contextual Integrity Norms in Language Models||
|2024| Privacy Checklist: Privacy Violation Detection Grounding on Contextual Integrity Theory||
|2024| Dynamic Neural Alignment Mechanisms in Large Language Models to Contextual Integrity Preservation||
|2024| Dynamic Neural Alignment Mechanisms in Large Language Models to Contextual Integrity Preservation ||
|2024| Privacy Agents: Utilizing Large Language Models to Safeguard Contextual Integrity in Elderly Care ||


## Related Papers
| Year | Paper | Dataset/Benchmark | Repository/Webpage 
|------| --- |-------------------| --- |
|2023|FANToM: A benchmark for stress-testing machine theory of mind in interactions| FANToM            |https://hyunw.kim/fantom